---
type: "docs"
title: "Sources"
linkTitle: "Sources"
weight: 40
description: >
    What are Sources and How to Use Them
---

Sources provide connectivity to the systems that Drasi can observe as sources of change. Sources perform three important functions within Drasi:
- Process the change log/feed generated by the source system and push those changes to each [Continuous Query](/solution-developer/components/continuous-queries) that uses that Source as input.
- Translate source change data into a consistent property graph data model so that subscribed Continuous Queries can use that data as if it where a graph of Nodes and Relations. For graph sources, such as Gremlin, no translation is necessary. But for non-graph sources, such as PostgreSQL and Kubernetes, the Source transforms the data (more detail is provided in the individual Sources sections below).
- Provide a way for Continuous Queries to query the source system at startup to initialize the state of the Continuous Query result.

{{< figure src="simple-end-to-end.png" alt="End to End" width="50%" >}}

Drasi currently provides Sources for the following source systems:

- [Azure Cosmos DB Gremlin API](#azure-cosmos-db-gremlin-api-source)
- [PostgreSQL](#postgresql-source)
- [Kubernetes](#kubernetes-source) (experimental)

## Creation
Sources are custom Kubernetes resources that you can create and manage using `Kubectl`. 

The easiest way to create a Source, and the way you will often create one as part of a broader software solution, is to:

1. Collect credentials and endpoint addresses that provide access to the change log and query API of the source system you want to connect to.
1. Create a YAML file containing the Source resource definition. This will include the configuration settings that enable the Source to connect to the source system. This file can be stored in your solution repo and versioned along with all the other solution code / resources.
1. Run `Kubectl` to apply the Source resource definition to the Kubernetes cluster where your Drasi environment is deployed.

As soon as the Source is created it will start running, monitoring its source system for changes and pushing them to subscribed Continuous Queries.

The Kubernetes resource definition for a Source has the following basic structure:

```
apiVersion: query.reactive-graph.io/v1
kind: Source
metadata:
  name: <id>
spec:
  sourceType: <type>
  properties: 
  - name: <property-name>
    value: <property-value>
  - ...
```
The following table describes these configuration settings:

|Name|Description|
|-|-|
|apiVersion|Must have the value **query.reactive-graph.io/v1**|
|kind|Must have the value **Source**|
|metadata.name|The **id** of the Source. Must be unique within the scope of the Sources in the Drasi deployment. The  **id** is used to manage the Source through Kubectl and in a Continuous Query definitions to identify which Sources the Continuous Query subscribes to for change events.|
|spec.sourceType|The type of Source to create, which defines the type of database or source system the Source connects to. Must be one of [CosmosGremlin](#azure-cosmos-db-gremlin-api-source), [PostgreSQL](#postgresql-source) or [Kubernetes](#kubernetes-source). Configuration settings specific to each of these Source types is described in the linked sections below.|
|spec.properties|The configuration settings passed to the Source as name-value pairs. Properties differ depending on the Source type (**spec.sourceType**). See the individual Source sections below for the properties required by each Source type.|

Once configured, to create a Source defined in a file called `source.yaml`, you would run the command:

```
kubectl apply -f source.yaml
```

You can then use the standard `Kubectl` commands to query the existence and status of the Source resource. For example, to see a list of the active Sources, run the following command:

```
kubectl get sources
```

## Deletion
To delete an active Source, run the following command:

```
kubectl delete source <id>
```

For example, if the Source ID is `human-resources`, you would run,

```
kubectl delete source human-resources
```

**Note**: Drasi does not currently enforce dependency integrity between Sources and Continuous Queries. If you delete a Source that is used by one or more Continuous Queries, they will stop getting change events and stop producing results.

## Configuring Sources
The following sections describe the configuration of the Source types currently supported by Drasi.

- [Azure Cosmos DB Gremlin API](#azure-cosmos-db-gremlin-api-source)
- [PostgreSQL](#postgresql-source)
- [Kubernetes](#kubernetes-source) (experimental)

### Azure Cosmos DB Gremlin API Source

The Azure Cosmos DB Gremlin API Source enables Drasi connectivity to Azure Cosmos DB Gremlin API. It uses the Cosmos DB Change Log as the source of database change events, and calls the Gremlin API to retrieve data required to bootstrap Continuous Queries at creation.

#### Source Requirements
For the Cosmos DB Gremlin Source to function, you must ensure the Full Fidelity Change Feed support is enabled on the Cosmos Account. Currently, this needs to be manually requested by [filling out this form](https://forms.office.com/pages/responsepage.aspx?id=v4j5cvGGr0GRqy180BHbR9ecQmQM5J5LlXYOPoIbyzdUOFVRNUlLUlpRV0dXMjFRNVFXMDNRRjVDNy4u).

#### Configuration Settings
The following is an example of a full resource definition for an Azure Cosmos DB Gremlin API Source using Kubernetes Secrets to securely store database credentials:


```
apiVersion: v1
kind: Secret
metadata:
  name: creds
type: Opaque
stringData:
  SourceAccountEndpoint: AccountEndpoint=...
  SourceKey: ...
---
apiVersion: query.reactive-graph.io/v1
kind: Source
metadata:
  name: retail-ops
spec:
  sourceType: CosmosGremlin
  properties: 
  - name: SourceAccountEndpoint
    valueFrom:
      secretKeyRef:
        name: creds
        key: SourceAccountEndpoint
  - name: SourceConnectionString
    value: wss://reactive-graph.gremlin.cosmos.azure.com:443/
  - name: SourceDatabaseName
    value: Contoso
  - name: SourceContainerName
    value: RetailOperations
  - name: SourceContainerPartitionKey
    value: name
  - name: SourceKey
    valueFrom:
      secretKeyRef:
        name: creds
        key: SourceKey
```

In the Source resource definition:
- **apiVersion** must be **query.reactive-graph.io/v1**
- **kind** must be **Source**
- **metadata.name** is the **id** of the Source and must be unique. This id is used in a Continuous Query definitions to identify which Sources the Continuous Query subscribes to for change events.
- **spec.sourceType** must be **CosmosGremlin**

The following table describes the properties that must be configured in the **spec.properties** array:
|Property|Description|
|-|-|
|SourceAccountEndpoint|The **PRIMARY** or **SECONDARY CONNECTION STRING** from the **Keys** page of the Azure Cosmsos DB Account page of the Azure Portal.|
|SourceKey|The **PRIMARY** or **SECONDARY KEY** from the **Keys** page of the Azure Cosmsos DB Account page of the Azure Portal. Must match the **SourceAccountEndpoint**.|
|SourceConnectionString|The **GREMLIN ENDPOINT** from the **Keys** page of the Azure Cosmsos DB Account page of the Azure Portal.|
|SourceDatabaseName|**Database Id** from the Cosmos DB account.|
|SourceContainerName|**Graph Id** from the Cosmos DB Database.|
|SourceContainerPartitionKey|The **Partition Key** configured on the **Graph**.|

#### Data Transformation
Cosmos DB Gremlin already uses a property graph data model and so the Source does not need to do any data transformation as it processes the inbound changes. The only thing to note is the terminology differences between Gremlin and Drasi summarized in this table:

|Gremlin Name|Drasi Name|
|-|-|
|Vertex|Node|
|Edge|Relation|

### PostgreSQL Source
The PostgreSQL Source enables Drasi connectivity to PostgreSQL databases. It uses the PostgreSQL replication log as the source of database change events, and calls the SQL API to retrieve data required to bootstrap Continuous Queries at creation.

#### Source Requirements

Your PostgreSQL database must be running at least version 10 and have `LOGICAL` replication enabled. You also need a PostgreSQL user that has at least the LOGIN, REPLICATION and CREATE permissions on the database and SELECT permissions on the tables you are interested in.

##### Azure Database for PostgreSQL

If you are using Azure Database for PostgreSQL, you can configure the replication to `LOGICAL` from the Azure portal under the `Replication` tab, or you can use the CLI as follows:

```azurecli
az postgres server configuration set --resource-group mygroup --server-name myserver --name azure.replication_support --value logical

az postgres server restart --resource-group mygroup --name myserver
```

##### Self Hosted PostgreSQL

First set the configuration options in postgresql.conf:

```
wal_level = logical
```

The other required settings have default values that are sufficient for a basic setup.

pg_hba.conf needs to be adjusted to allow replication (the values here depend on your actual network configuration and user you want to use for connecting):

```
host     all     repuser     0.0.0.0/0     md5
```

#### Configuration Settings
The following is an example of a full resource definition for a PostgreSQL Source using Kubernetes Secrets to securely store database credentials:


```
apiVersion: v1
kind: Secret
metadata:
  name: creds
type: Opaque
stringData:
  password: xxxxxx
---
apiVersion: query.reactive-graph.io/v1
kind: Source
metadata:
  name: phys-ops
spec:
  sourceType: PostgreSQL
  properties: 
  - name: database.hostname
    value: reactive-graph.postgres.database.azure.com
  - name: database.port
    value: "5432"
  - name: database.user
    value: postgres@reactive-graph
  - name: database.password
    valueFrom:
      secretKeyRef:
        name: creds
        key: password
  - name: database.dbname
    value: phys-ops
  - name: database.ssl
    value: "true"
  - name: tables
    value: public.Vehicle,public.Zone
```

In the Source resource definition:
- **apiVersion** must be **query.reactive-graph.io/v1**
- **kind** must be **Source**
- **metadata.name** is the **id** of the Source and must be unique. This id is used in a Continuous Query definitions to identify which Sources the Continuous Query subscribes to for change events.
- **spec.sourceType** must be **PostgreSQL**

The following table describes the properties that must be configured in the **spec.properties** array:
|Property|Description|
|-|-|
|database.hostname|The **host name** of the PostgreSQL database server.|
|database.port|The **port** number used to communicate with the PostgreSQL database server.|
|database.user|The **user id** to use for authentication against the PostgreSQL database server.|
|database.password|The **password** for the user account specified in the **database.user** property.|
|database.dbname|The name of the PostgreSQL database.|
|database.ssl|Does the server require a secure connection, valid values are "true" or "false".|
|tables| A comma separated list of table names that the Source should process changes for. Tables must have a **public.** prefix.|

#### Data Transformation
The PostgreSQL Source translates the relational data from change events to more closely resemble property graph data change events so that they can be processed by subscribed Continuous Queries. To achieve this, the PostgreSQL Source represents table rows as graph Nodes, as follows:
- Each row gets represented as a Node with the table columns as properties of the Node.
- The Node is assigned an id the is a composite of the table id and the row's primary key. This is Node metadata, not a property of the Node.
- The name of the table is assigned as a **Label** of the Node.

The PostgreSQL Source **does not** interpret foreign keys or joins from the relational source, instead relying on the Source Join feature provided by Continuous Queries to mimic graph-style Relations between Nodes based on the values of specified properties. See the [Source Joins](/solution-developer/components/continuous-queries/#source-subscriptions) topic in the [Continuous Queries](/solution-developer/components/continuous-queries) section for details. 

### Kubernetes Source
The Kubernetes Source is an early stage experimental Source that enables Drasi connectivity to Kubernetes clusters, enabling Drasi to support Continuous Queries that incorporate changes to Kubernetes resources.

#### Source Requirements

You will need a client side credentials that can be used to authenticate against your Kubernetes cluster and has permission to watch resources.

#### Configuration Settings
The following is an example of a full resource definition for a Kubernetes Source using Kubernetes Secrets to securely store credentials:

To get the credentials, export the Kubernetes credentials to a file named `credentials.yaml`

- For self hosted clusters, you can find this in your [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/) file
- For AKS, you can use this command
```bash
az aks get-credentials --resource-group <resource group> --name <cluster name> --file credentials.yaml
```

Create a secret named `k8s-context` from the `credentials.yaml` file

```bash
kubectl create secret generic k8s-context --from-file=credentials.yaml
```

```
apiVersion: query.reactive-graph.io/v1
kind: Source
metadata:
  name: k8s
spec:
  sourceType: Kubernetes
  properties: 
  - name: KUBECONFIG
    valueFrom:
      secretKeyRef:
        name: k8s-context
        key: credentials.yaml
```

In the Source resource definition:
- **apiVersion** must be **query.reactive-graph.io/v1**
- **kind** must be **Source**
- **metadata.name** is the **id** of the Source and must be unique. This id is used in a Continuous Query definitions to identify which Sources the Continuous Query subscribes to for change events.
- **spec.sourceType** must be **Kubernetes**

The following table describes the properties that must be configured in the **spec.properties** array:
|Property|Description|
|-|-|
|KUBECONFIG|A [kubeconfig](https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig) containing the credentials to connect to your cluster|

#### Data Transformation

Currently, only Pods and Containers are projected onto a graph schema.  The relation between them is labeled `HOSTS` and flows from the `Pod` to the `Container`.  A MATCH cypher clause that connects these would look as follows

```cypher
MATCH (p:Pod)-[:HOSTS]->(c:Container) 
```

The following properties are projected to the graph nodes

|Node Label|Property|Origin|
|-|-|-|
|Container|name|Pod.status.containerStatuses[].name|
|Container|image|Pod.status.containerStatuses[].image|
|Container|started|Pod.status.containerStatuses[].started|
|Container|ready|Pod.status.containerStatuses[].ready|
|Container|restartCount|Pod.status.containerStatuses[].restartCount|
|Container|state|Pod.status.containerStatuses[].state|
|Container|message|Pod.status.containerStatuses[].state.message|
|Container|reason|Pod.status.containerStatuses[].state.reason|
|Container|terminationMessage|Pod.status.containerStatuses[].lastState.terminated.message|
|Pod|name|Pod.metadata.name|
|Pod|podIP|Pod.status.podIP|
|Pod|phase|Pod.status.phase|
|Pod|message|Pod.status.message|
|Pod|hostIP|Pod.status.hostIP|
|Pod|reason|Pod.status.reason|
